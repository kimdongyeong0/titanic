{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-12T02:33:40.029086Z","iopub.execute_input":"2022-04-12T02:33:40.030067Z","iopub.status.idle":"2022-04-12T02:33:41.313284Z","shell.execute_reply.started":"2022-04-12T02:33:40.029938Z","shell.execute_reply":"2022-04-12T02:33:41.312284Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Some considerations","metadata":{}},{"cell_type":"markdown","source":"* We have already our dataset split into train - we might want at some point to do some kind of cross-training (and so re-merge those 2 datasets) to increase the accuracy of our model.  \n* We were provided with a simple heuristic looking at the result of a model if we assigned 'survived' to all the women (this is a starting benchmark to understand what could be the additional impact of our work)  \n* Every modification we'll be doing on the train dataset, we should do the same on the test dataset. \nLet's now look at the data","metadata":{}},{"cell_type":"markdown","source":"# Setting up some base variables","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.060749Z","iopub.execute_input":"2022-04-11T22:48:46.061036Z","iopub.status.idle":"2022-04-11T22:48:46.093501Z","shell.execute_reply.started":"2022-04-11T22:48:46.060998Z","shell.execute_reply":"2022-04-11T22:48:46.092606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.094818Z","iopub.execute_input":"2022-04-11T22:48:46.095367Z","iopub.status.idle":"2022-04-11T22:48:46.12637Z","shell.execute_reply.started":"2022-04-11T22:48:46.095335Z","shell.execute_reply":"2022-04-11T22:48:46.125543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this, we see that some fields won't be super useful. \n* The PassengerId seems to be a uniqueID assigned to each passenger so this cannot be used for our model \n* Survived will be what we will use for our model\n* PClass seems to be a good predictor of survival (knowing the story of the titanic)\n* Name could be interesting but we might need to clean the field and extract something like the title\n* Sex => very interesting (knowing the story)\n* SibSp => # of siblings or spouse on the boat. That's very interesting, it could be interesting to look at that / if people survived more if they were part of a family\n* Parch => same as above\n* Ticket seems similar to PassengerID but we should look into that in more details \n* Fare => interesting field\n* Cabin - we should look at null value and what that means (no cabin?)\n* Embarked is the pork of embarcation - I am not sure for now what that entails/how that can modify the model but there might be some reasons why it would, so for now let's keep it and keep studying the data\n","metadata":{}},{"cell_type":"markdown","source":"# Studying the NA","metadata":{}},{"cell_type":"markdown","source":"First step is to understand where are the NA and which strategy we could follow here to fill those NA","metadata":{}},{"cell_type":"code","source":"train_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:52:20.423928Z","iopub.execute_input":"2022-04-11T22:52:20.424263Z","iopub.status.idle":"2022-04-11T22:52:20.434435Z","shell.execute_reply.started":"2022-04-11T22:52:20.424228Z","shell.execute_reply":"2022-04-11T22:52:20.433534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that:\n* Cabin is mostly empty. For this reason we are recommending removing this field as it would be very difficult to recreate it (or maybe using the Fare/Embarked but then there is a question re:do we need this feature if we have enough information from other features)\n* for Age - this one is a bit trickier. we need to look into this feature a bit more to be able to decide what is gonna be the best. Mostly, there is possibly something that can be done using other features. We could use the average (what we have been doing for the first submission) but if - for instance - all the rows missing age are for children, then we would completely change the output of the model. \n* for Embarked - there are only 2 rows that are missing this information. We could assign them the mode - in case we discover this is an important feature. \n\nFor now, we'd like to run a quick model first to have a general benchmark against all our future models. In order to run a quick model, we'll use a few simple variables:\n* Pclass\n* Sex (need to encode it since not INT)\n* SibSp\n* Parch\n* Fare","metadata":{}},{"cell_type":"markdown","source":"# Creating a function to encode dummy variables","metadata":{}},{"cell_type":"code","source":"def dummy_encoded(df,array):\n    for i in array:\n        df[[i]] = df[[i]].astype(str)\n        encoding = pd.get_dummies(df[[i]])\n        df = pd.concat([\n            df.drop([i],axis=1),\n            encoding],\n            axis=1)\n    return df;","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.127342Z","iopub.execute_input":"2022-04-11T22:48:46.127728Z","iopub.status.idle":"2022-04-11T22:48:46.133329Z","shell.execute_reply.started":"2022-04-11T22:48:46.127694Z","shell.execute_reply":"2022-04-11T22:48:46.132746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding Dummy Variables","metadata":{}},{"cell_type":"markdown","source":"At this stage we are going to encode the dummy variables for the features we want to keep. We will also create a variable column_to_keep that will contain the new columns we want our first model to use","metadata":{}},{"cell_type":"code","source":"df_training = dummy_encoded(train_data,['Sex','Pclass'])\ncolumn_to_keep = ['Age','SibSp','Parch','Pclass_1','Pclass_2','Sex_male','Fare']\ndf_training_final = df_training[column_to_keep]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.134344Z","iopub.execute_input":"2022-04-11T22:48:46.134934Z","iopub.status.idle":"2022-04-11T22:48:46.160519Z","shell.execute_reply.started":"2022-04-11T22:48:46.134898Z","shell.execute_reply":"2022-04-11T22:48:46.159855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Filling the NA","metadata":{}},{"cell_type":"code","source":"df_training_final.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.161422Z","iopub.execute_input":"2022-04-11T22:48:46.162025Z","iopub.status.idle":"2022-04-11T22:48:46.16926Z","shell.execute_reply.started":"2022-04-11T22:48:46.161992Z","shell.execute_reply":"2022-04-11T22:48:46.168588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For Age, we have a consequent number of NA. To make it simple, we'll replace by the average of the column (Note => that's not necessarily the best way to do, in subsequent submission we should double check if this is the best strategy)","metadata":{}},{"cell_type":"code","source":"train_data.mean()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.170198Z","iopub.execute_input":"2022-04-11T22:48:46.170861Z","iopub.status.idle":"2022-04-11T22:48:46.186571Z","shell.execute_reply.started":"2022-04-11T22:48:46.170827Z","shell.execute_reply":"2022-04-11T22:48:46.185648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the above, the average age is ~29.6. We are going to round it to 30 and we are going to replace the NA by 30","metadata":{}},{"cell_type":"code","source":"training_set = df_training_final.fillna(30)\ntraining_set = pd.concat([training_set,train_data[['Survived']]],axis=1)\ntraining_set = training_set.astype(int)\ntraining_set.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.187853Z","iopub.execute_input":"2022-04-11T22:48:46.188139Z","iopub.status.idle":"2022-04-11T22:48:46.204532Z","shell.execute_reply.started":"2022-04-11T22:48:46.188108Z","shell.execute_reply":"2022-04-11T22:48:46.2037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a first model to get a benchmark (+first result)","metadata":{}},{"cell_type":"markdown","source":"To start with, we're going to create some kind of 'naive' model to understand exactly how precise/accurate a model could be without any refinement on the metric. Then we shall improve this model.\nThis is a classification problem here - so we'll use simple classification to try to build the model","metadata":{}},{"cell_type":"code","source":"reg = LogisticRegression()\nreg.fit(training_set[column_to_keep], training_set[\"Survived\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.207919Z","iopub.execute_input":"2022-04-11T22:48:46.208188Z","iopub.status.idle":"2022-04-11T22:48:46.246699Z","shell.execute_reply.started":"2022-04-11T22:48:46.208158Z","shell.execute_reply":"2022-04-11T22:48:46.245903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tn, fp, fn, tp = confusion_matrix(training_set[\"Survived\"], reg.predict(training_set[['Age','SibSp','Parch','Pclass_1','Pclass_2','Sex_male','Fare']])).ravel()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.248014Z","iopub.execute_input":"2022-04-11T22:48:46.248302Z","iopub.status.idle":"2022-04-11T22:48:46.258908Z","shell.execute_reply.started":"2022-04-11T22:48:46.248262Z","shell.execute_reply":"2022-04-11T22:48:46.25816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = (tp+tn)/(tp+tn+fp+fn)\nprecision = tp / (tp+fp)\nprint([accuracy,precision])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.260022Z","iopub.execute_input":"2022-04-11T22:48:46.260251Z","iopub.status.idle":"2022-04-11T22:48:46.270515Z","shell.execute_reply.started":"2022-04-11T22:48:46.260215Z","shell.execute_reply":"2022-04-11T22:48:46.269905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning Data for 1st submission","metadata":{}},{"cell_type":"markdown","source":"We are going to use this first model to do one submission here and have a first result on the problem we are trying to solve. But we can't directly run this on our test data, mostly because some fields seem to be missing","metadata":{}},{"cell_type":"markdown","source":"## Encoding the data + keeping the same features that we have in our model","metadata":{}},{"cell_type":"code","source":"df_test = dummy_encoded(test_data,['Sex','Pclass'])\ntest_set = df_test[column_to_keep]\ntest_set.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.271596Z","iopub.execute_input":"2022-04-11T22:48:46.271925Z","iopub.status.idle":"2022-04-11T22:48:46.304143Z","shell.execute_reply.started":"2022-04-11T22:48:46.271897Z","shell.execute_reply":"2022-04-11T22:48:46.303304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filling NA","metadata":{}},{"cell_type":"code","source":"test_set.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.306576Z","iopub.execute_input":"2022-04-11T22:48:46.307226Z","iopub.status.idle":"2022-04-11T22:48:46.314754Z","shell.execute_reply.started":"2022-04-11T22:48:46.307187Z","shell.execute_reply":"2022-04-11T22:48:46.314024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* For age, we will follow the same strategy that we followed previously (replace by 30)\n* For Fare, we are assuming that Fare is very related to the class you are in. For this reason we'll look at the average fare for the class of this passenger, and we'll use that here","metadata":{}},{"cell_type":"code","source":"test_set[test_set['Fare'].isna()]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.316062Z","iopub.execute_input":"2022-04-11T22:48:46.316429Z","iopub.status.idle":"2022-04-11T22:48:46.329916Z","shell.execute_reply.started":"2022-04-11T22:48:46.316389Z","shell.execute_reply":"2022-04-11T22:48:46.329059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This person was in class 3. Let's look at the average Fare for our passenger in Pclass 3","metadata":{}},{"cell_type":"code","source":"train_data.groupby('Pclass').mean()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.331229Z","iopub.execute_input":"2022-04-11T22:48:46.331606Z","iopub.status.idle":"2022-04-11T22:48:46.34784Z","shell.execute_reply.started":"2022-04-11T22:48:46.331563Z","shell.execute_reply":"2022-04-11T22:48:46.346989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to replace the Fare price, we are going to use the average of the price Fare for Pclass = 3","metadata":{}},{"cell_type":"code","source":"test_set[['Fare']] = test_set[['Fare']].fillna(13.7)\ntest_set[['Age']] = test_set[['Age']].fillna(30)\ntest_set.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.353303Z","iopub.execute_input":"2022-04-11T22:48:46.353549Z","iopub.status.idle":"2022-04-11T22:48:46.367571Z","shell.execute_reply.started":"2022-04-11T22:48:46.353519Z","shell.execute_reply":"2022-04-11T22:48:46.366598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the data for the submission","metadata":{}},{"cell_type":"code","source":"result = pd.concat([\n    test_data[['PassengerId']],\n    pd.DataFrame(reg.predict(test_set),columns=['Survived'])],\n    axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.369305Z","iopub.execute_input":"2022-04-11T22:48:46.369843Z","iopub.status.idle":"2022-04-11T22:48:46.378024Z","shell.execute_reply.started":"2022-04-11T22:48:46.369795Z","shell.execute_reply":"2022-04-11T22:48:46.377133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.to_csv('titanic_submission5.csv', index = False, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.379752Z","iopub.execute_input":"2022-04-11T22:48:46.380316Z","iopub.status.idle":"2022-04-11T22:48:46.389261Z","shell.execute_reply.started":"2022-04-11T22:48:46.380274Z","shell.execute_reply":"2022-04-11T22:48:46.388297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we end up with a score of **0.75837** - let's see how we can improve that","metadata":{}},{"cell_type":"markdown","source":"# Deep diving into the first model","metadata":{}},{"cell_type":"markdown","source":"From this past result there are a few strategies we could use:\n* rethinking the different features\n* trying different models\n\nLet's start with rethinking the different features","metadata":{}},{"cell_type":"markdown","source":"## Rethinking the different features","metadata":{}},{"cell_type":"markdown","source":"### Understanding the coef","metadata":{}},{"cell_type":"code","source":"coef_from_reg = pd.DataFrame(\n    data = reg.coef_,\n    columns = column_to_keep)\ncoef_from_reg.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.390384Z","iopub.execute_input":"2022-04-11T22:48:46.390875Z","iopub.status.idle":"2022-04-11T22:48:46.407069Z","shell.execute_reply.started":"2022-04-11T22:48:46.390842Z","shell.execute_reply":"2022-04-11T22:48:46.406458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this, it seems like the 'Fare' feature has the smallest impact on the model. We could consider removing it.<br> \nSame with age/parch it seems like => maybe we could transform this feature. <br>\nEspecially, we are thinking of coding a true/false flag for \"is a kid\" - based on the well-known adage 'Women and children first'. Also a flag 'is part of a family'\nFor kis => let's define it as anyone below 16","metadata":{}},{"cell_type":"code","source":"training_set['Is a Child'] = training_set['Age'] <= 16 \ntraining_set.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.4081Z","iopub.execute_input":"2022-04-11T22:48:46.408798Z","iopub.status.idle":"2022-04-11T22:48:46.422155Z","shell.execute_reply.started":"2022-04-11T22:48:46.408765Z","shell.execute_reply":"2022-04-11T22:48:46.421188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set2 = training_set.drop([\"Age\",\"Fare\"],axis=1)\ntraining_set2 = training_set2.astype(int)\ntraining_set2_wo_survived = training_set2.drop([\"Survived\"],axis=1)\ntraining_set2_wo_survived.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.423692Z","iopub.execute_input":"2022-04-11T22:48:46.424317Z","iopub.status.idle":"2022-04-11T22:48:46.438889Z","shell.execute_reply.started":"2022-04-11T22:48:46.42427Z","shell.execute_reply":"2022-04-11T22:48:46.43809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training a second model","metadata":{}},{"cell_type":"code","source":"reg2 = LogisticRegression()\nreg2.fit(training_set2_wo_survived, training_set2[\"Survived\"])\ntn2, fp2, fn2, tp2 = confusion_matrix(training_set2[\"Survived\"], reg2.predict(training_set2_wo_survived)).ravel()\naccuracy2 = (tp2+tn2)/(tp2+tn2+fp2+fn2)\nprecision2 = tp2 / (tp2+fp2)\nprint([accuracy2,precision2])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.030769Z","iopub.execute_input":"2022-04-11T22:48:46.03115Z","iopub.status.idle":"2022-04-11T22:48:46.050161Z","shell.execute_reply.started":"2022-04-11T22:48:46.03112Z","shell.execute_reply":"2022-04-11T22:48:46.049409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have a slightly higer accuracy and precision here - let's look at the coeff","metadata":{}},{"cell_type":"code","source":"coef_from_reg2 = pd.DataFrame(\n    data = reg2.coef_,\n    columns = training_set2_wo_survived.columns)\ncoef_from_reg2.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T22:48:46.440159Z","iopub.execute_input":"2022-04-11T22:48:46.44036Z","iopub.status.idle":"2022-04-11T22:48:46.451803Z","shell.execute_reply.started":"2022-04-11T22:48:46.440336Z","shell.execute_reply":"2022-04-11T22:48:46.451206Z"},"trusted":true},"execution_count":null,"outputs":[]}]}